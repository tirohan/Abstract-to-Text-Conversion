{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Abstract2Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:13:20.031848Z",
     "iopub.status.busy": "2021-11-19T13:13:20.031498Z",
     "iopub.status.idle": "2021-11-19T13:13:23.357558Z",
     "shell.execute_reply": "2021-11-19T13:13:23.356948Z",
     "shell.execute_reply.started": "2021-11-19T13:13:20.031781Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "import wandb\n",
    "from datasets import load_from_disk, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, \\\n",
    "                         DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/ubuntu/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/nerdimite/abstract-to-title/runs/2sbciy9p\" target=\"_blank\">fearless-brook-2</a></strong> to <a href=\"https://wandb.ai/nerdimite/abstract-to-title\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/nerdimite/abstract-to-title/runs/2sbciy9p?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fb5c9f52130>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace with your weights and biases username otherwise comment this\n",
    "wandb.init(project=\"abstract-to-title\", entity=\"nerdimite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:13:31.687885Z",
     "iopub.status.busy": "2021-11-19T13:13:31.687541Z",
     "iopub.status.idle": "2021-11-19T13:13:31.997391Z",
     "shell.execute_reply": "2021-11-19T13:13:31.996752Z",
     "shell.execute_reply.started": "2021-11-19T13:13:31.687860Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize T5-base tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:13:33.471738Z",
     "iopub.status.busy": "2021-11-19T13:13:33.471420Z",
     "iopub.status.idle": "2021-11-19T13:13:33.482045Z",
     "shell.execute_reply": "2021-11-19T13:13:33.481524Z",
     "shell.execute_reply.started": "2021-11-19T13:13:33.471714Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the processed data\n",
    "dataset = load_from_disk('arxiv_AI_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:13:34.314993Z",
     "iopub.status.busy": "2021-11-19T13:13:34.314678Z",
     "iopub.status.idle": "2021-11-19T13:13:34.317945Z",
     "shell.execute_reply": "2021-11-19T13:13:34.317360Z",
     "shell.execute_reply.started": "2021-11-19T13:13:34.314969Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_SOURCE_LEN = 512\n",
    "MAX_TARGET_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:13:34.969829Z",
     "iopub.status.busy": "2021-11-19T13:13:34.969512Z",
     "iopub.status.idle": "2021-11-19T13:13:34.974526Z",
     "shell.execute_reply": "2021-11-19T13:13:34.973868Z",
     "shell.execute_reply.started": "2021-11-19T13:13:34.969805Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(example):\n",
    "    \n",
    "    model_inputs = tokenizer(example['abstract'], max_length=MAX_SOURCE_LEN, padding=True, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(example['title'], max_length=MAX_TARGET_LEN, padding=True, truncation=True)\n",
    "\n",
    "    # Replace all pad token ids in the labels by -100 to ignore padding in the loss\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    model_inputs['labels'] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:13:36.373210Z",
     "iopub.status.busy": "2021-11-19T13:13:36.372893Z",
     "iopub.status.idle": "2021-11-19T13:13:37.342402Z",
     "shell.execute_reply": "2021-11-19T13:13:37.341857Z",
     "shell.execute_reply.started": "2021-11-19T13:13:36.373185Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at arxiv_AI_dataset/train/cache-f2dcdb2e692d508c.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf771efd9544a3dbb27dc46ed6e90ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at arxiv_AI_dataset/val/cache-e1ffc110fb199715.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels'],\n",
       "        num_rows: 36074\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels'],\n",
       "        num_rows: 2005\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels'],\n",
       "        num_rows: 2004\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocess_data() to the whole dataset\n",
    "processed_dataset = dataset.map(\n",
    "    preprocess_data,\n",
    "    batched=True,\n",
    "    remove_columns=['abstract', 'title'],\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "\n",
    "processed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:13:53.967268Z",
     "iopub.status.busy": "2021-11-19T13:13:53.966933Z",
     "iopub.status.idle": "2021-11-19T13:13:53.970713Z",
     "shell.execute_reply": "2021-11-19T13:13:53.970086Z",
     "shell.execute_reply.started": "2021-11-19T13:13:53.967244Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_epochs = 5\n",
    "learning_rate = 5.6e-5\n",
    "weight_decay = 0.01\n",
    "log_every = 50\n",
    "eval_every = 1000\n",
    "lr_scheduler_type = \"linear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:14:00.354699Z",
     "iopub.status.busy": "2021-11-19T13:14:00.354389Z",
     "iopub.status.idle": "2021-11-19T13:14:00.451642Z",
     "shell.execute_reply": "2021-11-19T13:14:00.451017Z",
     "shell.execute_reply.started": "2021-11-19T13:14:00.354676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"model-t5-base\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=eval_every,\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=weight_decay,\n",
    "    save_steps=500,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=num_epochs,\n",
    "    predict_with_generate=True,\n",
    "    logging_steps=log_every,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"wandb\",\n",
    "    resume_from_checkpoint=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:14:04.988628Z",
     "iopub.status.busy": "2021-11-19T13:14:04.988287Z",
     "iopub.status.idle": "2021-11-19T13:14:13.093681Z",
     "shell.execute_reply": "2021-11-19T13:14:13.093052Z",
     "shell.execute_reply.started": "2021-11-19T13:14:04.988588Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize T5-base model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:14:13.095116Z",
     "iopub.status.busy": "2021-11-19T13:14:13.094858Z",
     "iopub.status.idle": "2021-11-19T13:14:13.252834Z",
     "shell.execute_reply": "2021-11-19T13:14:13.252320Z",
     "shell.execute_reply.started": "2021-11-19T13:14:13.095096Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define ROGUE metrics on evaluation data\n",
    "metric = load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # ROUGE expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    # Compute ROUGE scores and get the median scores\n",
    "    result = metric.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:14:13.253756Z",
     "iopub.status.busy": "2021-11-19T13:14:13.253563Z",
     "iopub.status.idle": "2021-11-19T13:14:13.256642Z",
     "shell.execute_reply": "2021-11-19T13:14:13.256048Z",
     "shell.execute_reply.started": "2021-11-19T13:14:13.253738Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dynamic padding in batch using a data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:26:57.569948Z",
     "iopub.status.busy": "2021-11-19T13:26:57.569634Z",
     "iopub.status.idle": "2021-11-19T13:26:57.580471Z",
     "shell.execute_reply": "2021-11-19T13:26:57.579864Z",
     "shell.execute_reply.started": "2021-11-19T13:26:57.569925Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=processed_dataset[\"train\"],\n",
    "    eval_dataset=processed_dataset[\"val\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained('model-t5-base/checkpoint-6000/').to('cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained('model-t5-base/checkpoint-6000/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:27:03.756757Z",
     "iopub.status.busy": "2021-11-19T13:27:03.756436Z",
     "iopub.status.idle": "2021-11-19T13:30:44.492437Z",
     "shell.execute_reply": "2021-11-19T13:30:44.491895Z",
     "shell.execute_reply.started": "2021-11-19T13:27:03.756734Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2005\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='251' max='251' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [251/251 03:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 40s, sys: 194 ms, total: 3min 40s\n",
      "Wall time: 3min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.6707532405853271,\n",
       " 'eval_rouge1': 47.1746,\n",
       " 'eval_rouge2': 26.8231,\n",
       " 'eval_rougeL': 41.7727,\n",
       " 'eval_rougeLsum': 41.8263,\n",
       " 'eval_runtime': 220.717,\n",
       " 'eval_samples_per_second': 9.084,\n",
       " 'eval_steps_per_second': 1.137}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.evaluate(eval_dataset=processed_dataset['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:40:10.661400Z",
     "iopub.status.busy": "2021-11-19T13:40:10.661056Z",
     "iopub.status.idle": "2021-11-19T13:40:10.665897Z",
     "shell.execute_reply": "2021-11-19T13:40:10.665328Z",
     "shell.execute_reply.started": "2021-11-19T13:40:10.661377Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temperature = 0.9\n",
    "num_beams = 4\n",
    "max_gen_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T13:40:33.699612Z",
     "iopub.status.busy": "2021-11-19T13:40:33.699293Z",
     "iopub.status.idle": "2021-11-19T13:40:33.956567Z",
     "shell.execute_reply": "2021-11-19T13:40:33.955828Z",
     "shell.execute_reply.started": "2021-11-19T13:40:33.699588Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-Supervised Learning of Vision Transformers\n"
     ]
    }
   ],
   "source": [
    "abstract = \"\"\"In this paper, we question if self-supervised learning provides\n",
    "new properties to Vision Transformer (ViT) [19] that\n",
    "stand out compared to convolutional networks (convnets).\n",
    "Beyond the fact that adapting self-supervised methods to this\n",
    "architecture works particularly well, we make the following\n",
    "observations: first, self-supervised ViT features contain\n",
    "explicit information about the semantic segmentation of an\n",
    "image, which does not emerge as clearly with supervised\n",
    "ViTs, nor with convnets. Second, these features are also excellent\n",
    "k-NN classifiers, reaching 78.3% top-1 on ImageNet\n",
    "with a small ViT. Our study also underlines the importance of\n",
    "momentum encoder [33], multi-crop training [10], and the\n",
    "use of small patches with ViTs. We implement our findings\n",
    "into a simple self-supervised method, called DINO, which\n",
    "we interpret as a form of self-distillation with no labels.\n",
    "We show the synergy between DINO and ViTs by achieving\n",
    "80.1% top-1 on ImageNet in linear evaluation with ViT-Base\"\"\"\n",
    "# abstract = dataset['test'][0]['abstract']\n",
    "inputs = tokenizer([abstract], max_length=512, return_tensors='pt')\n",
    "\n",
    "title_ids = model.generate(\n",
    "    inputs['input_ids'].to('cuda'), \n",
    "    num_beams=num_beams, \n",
    "    temperature=temperature, \n",
    "    max_length=max_gen_length, \n",
    "    early_stopping=True\n",
    ")\n",
    "title = tokenizer.decode(title_ids[0].tolist(), skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60fbf1aecf0122793952a73a80d27bc8732eff9e143c13520ca117508929b1c7"
  },
  "kernelspec": {
   "display_name": "PyTorch 1.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0011af7c2a1a44b2b86abd139850f8f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "00168cc339ab4d37bbf040239346f903": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_defd01d3f3ce4fd3acfacdbdbcdd8f9d",
       "max": 3,
       "style": "IPY_MODEL_34cbfddb6b144f3ea35715463b35bd66",
       "value": 3
      }
     },
     "081ac6d06e7e4919809f7e82727bc225": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0ec3e0d84bd34eafb11c47988ab761e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "27e916e2e74f4290842a5366fb2c90ec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "294259e3f56a4734a38a217a643a3b7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "34cbfddb6b144f3ea35715463b35bd66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "46e8db13110847b09b31493bf1aef00f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_aa058a5707324fd69649260c3fa49354",
       "style": "IPY_MODEL_081ac6d06e7e4919809f7e82727bc225",
       "value": "Running tokenizer on dataset: 100%"
      }
     },
     "599b4af1fcf4439e97ba4eef14b0f308": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_bdb7c24b9d4e468a966ce332f01cacdd",
       "style": "IPY_MODEL_e872f51fbed0454e9f426a640e046d7a"
      }
     },
     "6077e6bc33064f14819ec0f99f3e0987": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_0ec3e0d84bd34eafb11c47988ab761e3",
       "max": 1,
       "style": "IPY_MODEL_294259e3f56a4734a38a217a643a3b7f"
      }
     },
     "71fec538988d4f5cb2bbc51a305dc559": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "98ba5b3a839a4d92ae7559367819272a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "aa058a5707324fd69649260c3fa49354": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "aef8e4636f5548918a4bbf164e7dfd50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_27e916e2e74f4290842a5366fb2c90ec",
       "style": "IPY_MODEL_71fec538988d4f5cb2bbc51a305dc559",
       "value": " 3/3 [00:00&lt;00:00,  2.22ba/s]"
      }
     },
     "bbf771efd9544a3dbb27dc46ed6e90ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_46e8db13110847b09b31493bf1aef00f",
        "IPY_MODEL_00168cc339ab4d37bbf040239346f903",
        "IPY_MODEL_aef8e4636f5548918a4bbf164e7dfd50"
       ],
       "layout": "IPY_MODEL_98ba5b3a839a4d92ae7559367819272a"
      }
     },
     "bdb7c24b9d4e468a966ce332f01cacdd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cc3ab1576d874b44837b3aa95e2f23d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_599b4af1fcf4439e97ba4eef14b0f308",
        "IPY_MODEL_6077e6bc33064f14819ec0f99f3e0987"
       ],
       "layout": "IPY_MODEL_0011af7c2a1a44b2b86abd139850f8f5"
      }
     },
     "defd01d3f3ce4fd3acfacdbdbcdd8f9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e872f51fbed0454e9f426a640e046d7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
